{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, transforms, models\n",
    "import torch.nn.functional as F\n",
    "import timeit\n",
    "import time\n",
    "from skimage import io, transform\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from __future__ import division, print_function\n",
    "import shutil\n",
    "%matplotlib inline\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The model FCNS 32\n",
    "class fcns32(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self, n_classes =21, learn_bilinear=False):\n",
    "        super(fcns32, self).__init__()\n",
    "        self.learn_bilinear = learn_bilinear\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        # Creating the convolutional blocks\n",
    "        self.conv1block = nn.Sequential(\n",
    "                            nn.Conv2d(3, 64, 3, padding=100),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv2d(64, 64, 3, padding=1),\n",
    "                            nn.ReLU(),\n",
    "                            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n",
    "                            )\n",
    "        self.conv2block = nn.Sequential(\n",
    "                            nn.Conv2d(64, 128, 3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv2d(128, 128, 3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.MaxPool2d(2, stride=2, ceil_mode=True),)\n",
    "        self.conv3block = nn.Sequential(\n",
    "                            nn.Conv2d(128, 256, 3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv2d(256,256,3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv2d(256,256,3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n",
    "                            )\n",
    "        self.conv4block = nn.Sequential(\n",
    "                            nn.Conv2d(256, 512, 3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv2d(512,512,3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv2d(512,512,3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n",
    "                            )\n",
    "        self.conv5block = nn.Sequential(\n",
    "                            nn.Conv2d(512, 512, 3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv2d(512,512,3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv2d(512,512,3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n",
    "                            )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "                            nn.Conv2d(512, 4096, 7),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Dropout2d(),\n",
    "                            nn.Conv2d(4096, 4096, 1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Dropout2d(),\n",
    "                            nn.Conv2d(4096, n_classes, 1),\n",
    "                            )\n",
    "        \n",
    "    \n",
    "    # The forward pass\n",
    "    def forward(self, x):\n",
    "        conv1 = self.conv1block(x)\n",
    "        conv2 = self.conv2block(conv1)\n",
    "        conv3 = self.conv3block(conv2)\n",
    "        conv4 = self.conv4block(conv3)\n",
    "        conv5 = self.conv5block(conv4)\n",
    "        \n",
    "        output = self.classifier(conv5)\n",
    "        \n",
    "        out = F.upsample_bilinear(output, x.size()[2:])\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    #Using the pretrained network\n",
    "    def init_vgg16_params(self, vgg16, copy_fc8=True):\n",
    "        blocks = [self.conv1block,\n",
    "                 self.conv2block,\n",
    "                 self.conv3block,\n",
    "                 self.conv4block,\n",
    "                 self.conv5block]\n",
    "        \n",
    "        ranges = [[0,4], [5,9], [10, 16], [17, 23], [24, 29]]\n",
    "        features = list(vgg16.features.children())\n",
    "        print(features)\n",
    "        \n",
    "        for i, conv in enumerate(blocks):\n",
    "            for l1, l2 in zip(features[ranges[i][0]:ranges[i][1]], conv):\n",
    "                if isinstance(l1, nn.Conv2d) and isinstance(l2, nn.Conv2d):\n",
    "                    print(l1.weight.size(), i)\n",
    "                    print(l2.weight.size(), i)\n",
    "                    assert l1.weight.size() == l2.weight.size()\n",
    "                    assert l1.bias.size() == l2.bias.size()\n",
    "                    l2.weight.data = l1.weight.data\n",
    "                    l2.bias.data = l1.bias.data\n",
    "        \n",
    "        for i1, i2 in zip([0,3], [0,3]):\n",
    "            l1 = vgg16.classifier[i1]\n",
    "            l2 = self.classifier[i2]\n",
    "            l2.weight.data = l1.weight.data.view(l2.weight.size())\n",
    "            l2.bias.data = l1.bias.data.view(l2.bias.size())\n",
    "            \n",
    "        n_class = self.classifier[6].weight.size()[0]\n",
    "        \n",
    "        if copy_fc8:\n",
    "            l1 = vgg16.classifier[6]\n",
    "            l2 = self.classifier[6]\n",
    "            l2.weight.data = l1.weight.data[:n_class, :].view(l2.weight.size())\n",
    "            l2.bias.data = l1.bias.data[:n_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, criterion, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (inplace), Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (inplace), MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1)), Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (inplace), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (inplace), MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1)), Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (inplace), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (inplace), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (inplace), MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1)), Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (inplace), MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1)), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (inplace), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), ReLU (inplace), MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))]\n",
      "torch.Size([64, 3, 3, 3]) 0\n",
      "torch.Size([64, 3, 3, 3]) 0\n",
      "torch.Size([64, 64, 3, 3]) 0\n",
      "torch.Size([64, 64, 3, 3]) 0\n",
      "torch.Size([128, 64, 3, 3]) 1\n",
      "torch.Size([128, 64, 3, 3]) 1\n",
      "torch.Size([128, 128, 3, 3]) 1\n",
      "torch.Size([128, 128, 3, 3]) 1\n",
      "torch.Size([256, 128, 3, 3]) 2\n",
      "torch.Size([256, 128, 3, 3]) 2\n",
      "torch.Size([256, 256, 3, 3]) 2\n",
      "torch.Size([256, 256, 3, 3]) 2\n",
      "torch.Size([256, 256, 3, 3]) 2\n",
      "torch.Size([256, 256, 3, 3]) 2\n",
      "torch.Size([512, 256, 3, 3]) 3\n",
      "torch.Size([512, 256, 3, 3]) 3\n",
      "torch.Size([512, 512, 3, 3]) 3\n",
      "torch.Size([512, 512, 3, 3]) 3\n",
      "torch.Size([512, 512, 3, 3]) 3\n",
      "torch.Size([512, 512, 3, 3]) 3\n",
      "torch.Size([512, 512, 3, 3]) 4\n",
      "torch.Size([512, 512, 3, 3]) 4\n",
      "torch.Size([512, 512, 3, 3]) 4\n",
      "torch.Size([512, 512, 3, 3]) 4\n",
      "torch.Size([512, 512, 3, 3]) 4\n",
      "torch.Size([512, 512, 3, 3]) 4\n"
     ]
    }
   ],
   "source": [
    "model = fcns32()\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "model.init_vgg16_params(vgg16)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=0.7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data collection for training set\n",
    "\n",
    "trainText = '/Users/navneetmkumar/Documents/Paper Implementations/VOC2012/ImageSets/Segmentation/train.txt'\n",
    "\n",
    "def getTrainNames(filename):\n",
    "    segment_images = []\n",
    "    f = open(filename)\n",
    "    filecontents = f.readlines()\n",
    "    for line in filecontents:\n",
    "        img_name = line.strip('\\n')\n",
    "        segment_images.append(img_name)\n",
    "    return segment_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1464\n"
     ]
    }
   ],
   "source": [
    "train_images = getTrainNames(trainText)\n",
    "print(len(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('/Users/navneetmkumar/Documents/Paper Implementations/train-inputs'):\n",
    "    os.makedirs('/Users/navneetmkumar/Documents/Paper Implementations/train-inputs')\n",
    "\n",
    "if not os.path.exists('/Users/navneetmkumar/Documents/Paper Implementations/train-targets'):\n",
    "    os.makedirs('/Users/navneetmkumar/Documents/Paper Implementations/train-targets')\n",
    "\n",
    "image_dir = '/Users/navneetmkumar/Documents/Paper Implementations/VOC2012/JPEGImages'\n",
    "targets_dir = '/Users/navneetmkumar/Documents/Paper Implementations/VOC2012/SegmentationClass'\n",
    "\n",
    "def copyFiles(directory, targets=False):\n",
    "    for f in os.listdir(directory):\n",
    "        f_name = os.path.basename(f)\n",
    "        f_name = f_name.split(\".\")[0]\n",
    "        if f_name in train_images:\n",
    "            f = os.path.join(directory, f)\n",
    "            if targets:\n",
    "                shutil.copy2(f, '/Users/navneetmkumar/Documents/Paper Implementations/train-targets/')\n",
    "            else:\n",
    "                shutil.copy2(f, '/Users/navneetmkumar/Documents/Paper Implementations/train-inputs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "copyFiles(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "copyFiles(targets_dir, targets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1449\n"
     ]
    }
   ],
   "source": [
    "# Setting up the validation set\n",
    "valText = '/Users/navneetmkumar/Documents/Paper Implementations/VOC2012/ImageSets/Segmentation/val.txt'\n",
    "val_images = getTrainNames(valText)\n",
    "print(len(val_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('/Users/navneetmkumar/Documents/Paper Implementations/val-inputs'):\n",
    "    os.makedirs('/Users/navneetmkumar/Documents/Paper Implementations/val-inputs')\n",
    "\n",
    "if not os.path.exists('/Users/navneetmkumar/Documents/Paper Implementations/val-targets'):\n",
    "    os.makedirs('/Users/navneetmkumar/Documents/Paper Implementations/val-targets')\n",
    "\n",
    "image_dir = '/Users/navneetmkumar/Documents/Paper Implementations/VOC2012/JPEGImages'\n",
    "targets_dir = '/Users/navneetmkumar/Documents/Paper Implementations/VOC2012/SegmentationClass'\n",
    "\n",
    "def copyFiles(directory, targets=False):\n",
    "    for f in os.listdir(directory):\n",
    "        f_name = os.path.basename(f)\n",
    "        f_name = f_name.split(\".\")[0]\n",
    "        if f_name in val_images:\n",
    "            f = os.path.join(directory, f)\n",
    "            if targets:\n",
    "                shutil.copy2(f, '/Users/navneetmkumar/Documents/Paper Implementations/val-targets/')\n",
    "            else:\n",
    "                shutil.copy2(f, '/Users/navneetmkumar/Documents/Paper Implementations/val-inputs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "copyFiles(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "copyFiles(targets_dir, targets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display the validation images\n",
    "val_im_dir = '/Users/navneetmkumar/Documents/Paper Implementations/val-inputs'\n",
    "val_t_dir = '/Users/navneetmkumar/Documents/Paper Implementations/val-targets'\n",
    "\n",
    "val_im_list = glob.glob(os.path.join(val_im_dir, '*.jpg'))\n",
    "val_t_list = glob.glob(os.path.join(val_t_dir, '*.png'))\n",
    "\n",
    "def showImage(image, dire):\n",
    "    f = os.path.join(dire, image)\n",
    "    plt.imshow(io.imread(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
