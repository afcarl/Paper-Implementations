{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lung Cancer Detection using a 3d Convolutional Network\n",
    "We will be implementing a 3d convnet and possibly a vnet later on to test on the lung cancer dataset provided in the\n",
    "kaggle data bowl 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dicom\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import timeit\n",
    "import time\n",
    "from skimage import transform, io\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from __future__ import division, print_function\n",
    "import shutil\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import torchvision.transforms as T\n",
    "from torchvision import utils\n",
    "import scipy.misc as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining the data directories\n",
    "root_dir = '/Users/navneetmkumar/Documents/Paper Implementations'\n",
    "sample_images_dir = root_dir+'/sample_images'\n",
    "patients = os.listdir(sample_images_dir)\n",
    "labels = pd.read_csv('/Volumes/Nav/Datasets/stage1_labels.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  cancer\n",
      "id                                      \n",
      "0015ceb851d7251b8f399e39779d1e7d       1\n",
      "0030a160d58723ff36d73f41b170ec21       0\n",
      "003f41c78e6acfa92430a057ac0b306e       0\n",
      "006b96310a37b36cccb2ab48d10b49a3       1\n",
      "008464bb8521d09a42985dd8add3d0d2       1\n"
     ]
    }
   ],
   "source": [
    "print(labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 0\n",
      "(0008, 0005) Specific Character Set              CS: 'ISO_IR 100'\n",
      "(0008, 0016) SOP Class UID                       UI: CT Image Storage\n",
      "(0008, 0018) SOP Instance UID                    UI: 1.2.840.113654.2.55.172417057944294031327929824889848320186\n",
      "(0008, 0060) Modality                            CS: 'CT'\n",
      "(0008, 103e) Series Description                  LO: 'Axial'\n",
      "(0010, 0010) Patient's Name                      PN: '0a38e7597ca26f9374f8ea2770ba870d'\n",
      "(0010, 0020) Patient ID                          LO: '0a38e7597ca26f9374f8ea2770ba870d'\n",
      "(0010, 0030) Patient's Birth Date                DA: '19000101'\n",
      "(0018, 0060) KVP                                 DS: ''\n",
      "(0020, 000d) Study Instance UID                  UI: 2.25.13148394979245937484165594540025668927189308811493143066650\n",
      "(0020, 000e) Series Instance UID                 UI: 2.25.53298563728906335585833752405238884704498238267638676785109\n",
      "(0020, 0011) Series Number                       IS: '2'\n",
      "(0020, 0012) Acquisition Number                  IS: '1'\n",
      "(0020, 0013) Instance Number                     IS: '110'\n",
      "(0020, 0020) Patient Orientation                 CS: ''\n",
      "(0020, 0032) Image Position (Patient)            DS: ['-172.500000', '-176.100006', '-244.540009']\n",
      "(0020, 0037) Image Orientation (Patient)         DS: ['1.000000', '0.000000', '0.000000', '0.000000', '1.000000', '0.000000']\n",
      "(0020, 0052) Frame of Reference UID              UI: 2.25.11642995668189613829999863683865722098177327703743652111991\n",
      "(0020, 1040) Position Reference Indicator        LO: 'SN'\n",
      "(0020, 1041) Slice Location                      DS: '-244.540009'\n",
      "(0028, 0002) Samples per Pixel                   US: 1\n",
      "(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n",
      "(0028, 0010) Rows                                US: 512\n",
      "(0028, 0011) Columns                             US: 512\n",
      "(0028, 0030) Pixel Spacing                       DS: ['0.625000', '0.625000']\n",
      "(0028, 0100) Bits Allocated                      US: 16\n",
      "(0028, 0101) Bits Stored                         US: 16\n",
      "(0028, 0102) High Bit                            US: 15\n",
      "(0028, 0103) Pixel Representation                US: 1\n",
      "(0028, 0120) Pixel Padding Value                 US: 63536\n",
      "(0028, 1050) Window Center                       DS: '40'\n",
      "(0028, 1051) Window Width                        DS: '350'\n",
      "(0028, 1052) Rescale Intercept                   DS: '-1024'\n",
      "(0028, 1053) Rescale Slope                       DS: '1'\n",
      "(7fe0, 0010) Pixel Data                          OW: Array of 524288 bytes\n"
     ]
    }
   ],
   "source": [
    "for patient in patients[:1]:\n",
    "    label = labels.get_value(patient, 'cancer')\n",
    "    path = os.path.join(sample_images_dir, patient)\n",
    "    slices = [dicom.read_file(path+'/'+s) for s in os.listdir(path)] # Get all the dicom files for the particular patient\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "    print(len(slices), label)\n",
    "    print(slices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "\n",
    "\n",
    "IMG_SIZE=50\n",
    "NUM_SLICES = 20\n",
    "\n",
    "# Create chunks of the data\n",
    "def chunks(l, n):\n",
    "    \"\"\" Yields successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i+n]\n",
    "        \n",
    "def mean(l):\n",
    "    return sum(l)/len(l)\n",
    "\n",
    "def process_data(patient, labels, img_px=50, num_slices=20, visualize=False):\n",
    "    label = labels.get_value(patient, 'cancer')\n",
    "    path = os.path.join(sample_images_dir, patient)\n",
    "    slices = [dicom.read_file(path+'/'+s) for s in os.listdir(path)] # Get all the dicom files for the particular patient\n",
    "    slices.sort(key = lambda x: int(x.ImagePositionPatient[2]))\n",
    "    \n",
    "    new_slices = []\n",
    "    slices = [cv2.resize(np.array(each_slice.pixel_array), (IMG_SIZE, IMG_SIZE)) for each_slice in slices]\n",
    "    chunk_size = math.ceil(len(slices)/NUM_SLICES)\n",
    "    \n",
    "    for slice_chunk in chunks(slices, chunk_size):\n",
    "        slice_chunk =  list(map(mean, zip(*slice_chunk)))\n",
    "        new_slices.append(slice_chunk)\n",
    "    \n",
    "    if len(new_slices) == NUM_SLICES-1:\n",
    "        new_slices.append(new_slices[-1])\n",
    "        \n",
    "    if len(new_slices) == NUM_SLICES-2:\n",
    "        new_slices.append(new_slices[-1])\n",
    "        new_slices.append(new_slices[-1])\n",
    "        \n",
    "    if len(new_slices) == NUM_SLICES+2:\n",
    "        new_val = list(map(mean, zip(*[new_slices[NUM_SLICES-1], new_slices[NUM_SLICES]])))\n",
    "        del new_slices[NUM_SLICES]\n",
    "        new_slices[NUM_SLICES-1]= new_val\n",
    "        \n",
    "    if len(new_slices) == NUM_SLICES+1:\n",
    "        new_val = list(map(mean, zip(*[new_slices[NUM_SLICES-1], new_slices[NUM_SLICES]])))\n",
    "        del new_slices[NUM_SLICES]\n",
    "        new_slices[NUM_SLICES-1]= new_val\n",
    "        \n",
    "    if visualize:\n",
    "        fig = plt.figure()\n",
    "        for num, each_slice in enumerate(new_slices):\n",
    "            y = fig.add_subplot(4,5, num+1)\n",
    "            y.imshow(each_slice)\n",
    "        plt.show()\n",
    "        \n",
    "    if label==1:\n",
    "        label = np.array([0,1])\n",
    "    elif label==0:\n",
    "        label = np.array([1,0])\n",
    "        \n",
    "    return np.array(new_slices), label\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:02,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is unlabeled data\n",
      "This is unlabeled data"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:24,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_data = []\n",
    "for num, patient in tqdm(enumerate(patients)):\n",
    "    try:\n",
    "        img_data, label = process_data(patient, labels)\n",
    "        new_data.append([img_data, label])\n",
    "    except KeyError as e:\n",
    "        print('This is unlabeled data')\n",
    "        \n",
    "np.save('train_data.npy', new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "data = np.load('train_data.npy')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Developing the dataloader\n",
    "class LungCancerDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, train_data, n_classes=2, is_transform=False):\n",
    "        self.train_data = train_data\n",
    "        self.n_classes = n_classes\n",
    "        self.is_transform = is_transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.train_data)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        img = self.train_data[i][0]\n",
    "        lbl = self.train_data[i][1]\n",
    "        sample  = {'image': img, 'target': lbl}\n",
    "        if self.is_transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def transform(self, sample):\n",
    "        img = sample['image']\n",
    "        lbl = sample['target']\n",
    "        \n",
    "        img = torch.from_numpy(img).float()\n",
    "        lbl = torch.from_numpy(lbl).long()\n",
    "        \n",
    "        sample  = {'image': img, 'target': lbl}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = LungCancerDataset(data, is_transform=True)\n",
    "# Instead of using a simple for loop we will be using the torch.utils.DataLoader\n",
    "# It provides the following features:\n",
    "# 1.Batching the data\n",
    "# 2.Shuffling the data\n",
    "# 3.Load data in parallel using multiprocessing workers\n",
    "\n",
    "dataloader = DataLoader(d, batch_size=10, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    imgs, labels = sample_batched['image'], sample_batched['target']\n",
    "    if i_batch == 0:\n",
    "        d = imgs[0].numpy()\n",
    "        print(d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "IMG_SIZE = 50\n",
    "NUM_SLICES = 20\n",
    "\n",
    "n_classes = 2\n",
    "\n",
    "class Convolutional3DNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_classes=2):\n",
    "        super(Convolutional3DNetwork, self).__init__()\n",
    "        self.n_classes =  n_classes\n",
    "        \n",
    "        self.conv1block = nn.Sequential(\n",
    "                            nn.Conv3d(20, 32, 3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv3d(32, 32, 3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.MaxPool3d(2, ceil_mode=True),\n",
    "                            )\n",
    "        self.conv2block = nn.Sequential(\n",
    "                            nn.Conv3d(32, 64, 3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv3d(64, 64, 3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.MaxPool3d(2, stride=2, ceil_mode=True),\n",
    "                            )\n",
    "        \n",
    "        self.conv3block = nn.Sequential(\n",
    "                            nn.Conv3d(64, 128, 3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.Conv3d(128, 128, 3, padding=1),\n",
    "                            nn.ReLU(inplace=True),\n",
    "                            nn.MaxPool3d(2, stride=2, ceil_mode=True),\n",
    "                            )\n",
    "        self.classifer = nn.Linear(6272, 2)\n",
    "        \n",
    "    # Define the forward pass for the network\n",
    "    def forward(self, x):\n",
    "        x = x.view([-1, NUM_SLICES, 1, IMG_SIZE, IMG_SIZE])\n",
    "        print(x.size())\n",
    "        conv1 = self.conv1block(x)\n",
    "        print(conv1.size())\n",
    "        conv2 = self.conv2block(conv1)\n",
    "        print(conv2.size())\n",
    "        conv3 = self.conv3block(conv2)\n",
    "        print(conv3.size())\n",
    "        conv3 = conv3.view(-1, 6272)\n",
    "        output = self.classifer(conv3)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the training method\n",
    "def train_model(model, optimizer, criterion, scheduler, num_epochs = 25):\n",
    "    since = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "                \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for data in dataloader:\n",
    "            inputs, labels = data['image'], data['target']\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            labels=labels[:,0]\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "            #Forward Pass\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            running_loss += loss.data[0]\n",
    "        \n",
    "        epoch_loss = running_loss / len(data)\n",
    "        \n",
    "        print('Loss: {:.4f}'.format(epoch_loss))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.2552\n",
      "Epoch 1/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.9152\n",
      "Epoch 2/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.9174\n",
      "Epoch 3/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.9136\n",
      "Epoch 4/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.9158\n",
      "Epoch 5/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.9162\n",
      "Epoch 6/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.9167\n",
      "Epoch 7/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.9128\n",
      "Epoch 8/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.9162\n",
      "Epoch 9/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.9164\n",
      "Epoch 10/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.9177\n",
      "Epoch 11/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.9214\n",
      "Epoch 12/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.9145\n",
      "Epoch 13/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.9186\n",
      "Epoch 14/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.9181\n",
      "Epoch 15/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])\n",
      "torch.Size([9, 32, 1, 25, 25])\n",
      "torch.Size([9, 64, 1, 13, 13])\n",
      "torch.Size([9, 128, 1, 7, 7])\n",
      "Loss: -0.9167\n",
      "Epoch 16/24\n",
      "----------\n",
      "torch.Size([10, 20, 1, 50, 50])\n",
      "torch.Size([10, 32, 1, 25, 25])\n",
      "torch.Size([10, 64, 1, 13, 13])\n",
      "torch.Size([10, 128, 1, 7, 7])\n",
      "torch.Size([9, 20, 1, 50, 50])"
     ]
    }
   ],
   "source": [
    "model = Convolutional3DNetwork()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=0.3, gamma=0.1)\n",
    "model  = train_model(model, optimizer, criterion, lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 111.2707  137.0363\n",
       "[torch.FloatTensor of size 1x2]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(Variable(torch.from_numpy(data[10][0]).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
